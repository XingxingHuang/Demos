{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These materia are from linkedin ([Building a Recommendation System with Python Machine Learning & AI](https://www.linkedin.com/learning/building-a-recommendation-system-with-python-machine-learning-ai))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Simple Approaches to Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations based on counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets are hosted on: https://archive.ics.uci.edu/ml/datasets/Restaurant+%26+consumer+data\n",
    "They were originally published by: Blanca Vargas-Govea, Juan Gabriel GonzÃ¡lez-Serna, Rafael Ponce-MedellÃ­n. Effects of relevant contextual features in the performance of a restaurant recommender system. In RecSysâ€™11: Workshop on Context Aware Recommender Systems (CARS-2011), Chicago, IL, USA, October 23, 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame = pd.read_csv('rating_final.csv')\n",
    "cuisine = pd.read_csv('chefmozcuisine.csv')\n",
    "geodata = pd.read_csv('geoplaces2.csv')#, encoding = 'mbcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>placeID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135085</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132825</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135032</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135052</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132834</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating\n",
       "placeID        \n",
       "135085       36\n",
       "132825       32\n",
       "135032       28\n",
       "135052       25\n",
       "132834       25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_count = pd.DataFrame(frame.groupby('placeID')['rating'].count())\n",
    "\n",
    "rating_count.sort_values('rating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeID</th>\n",
       "      <th>Rcuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135085</td>\n",
       "      <td>Fast_Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132825</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135032</td>\n",
       "      <td>Cafeteria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135032</td>\n",
       "      <td>Contemporary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135052</td>\n",
       "      <td>Bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>135052</td>\n",
       "      <td>Bar_Pub_Brewery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132834</td>\n",
       "      <td>Mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   placeID         Rcuisine\n",
       "0   135085        Fast_Food\n",
       "1   132825          Mexican\n",
       "2   135032        Cafeteria\n",
       "3   135032     Contemporary\n",
       "4   135052              Bar\n",
       "5   135052  Bar_Pub_Brewery\n",
       "6   132834          Mexican"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_rated_places = pd.DataFrame([135085, 132825, 135032, 135052, 132834], index=np.arange(5), columns=['placeID'])\n",
    "\n",
    "summary = pd.merge(most_rated_places, cuisine, on='placeID')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Recommendations Based on Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>placeID</th>\n",
       "      <th>132560</th>\n",
       "      <th>132561</th>\n",
       "      <th>132564</th>\n",
       "      <th>132572</th>\n",
       "      <th>132583</th>\n",
       "      <th>132584</th>\n",
       "      <th>132594</th>\n",
       "      <th>132608</th>\n",
       "      <th>132609</th>\n",
       "      <th>132613</th>\n",
       "      <th>...</th>\n",
       "      <th>135080</th>\n",
       "      <th>135081</th>\n",
       "      <th>135082</th>\n",
       "      <th>135085</th>\n",
       "      <th>135086</th>\n",
       "      <th>135088</th>\n",
       "      <th>135104</th>\n",
       "      <th>135106</th>\n",
       "      <th>135108</th>\n",
       "      <th>135109</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U1001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "placeID  132560  132561  132564  132572  132583  132584  132594  132608  \\\n",
       "userID                                                                    \n",
       "U1001       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "U1002       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "U1003       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "U1004       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "U1005       NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "placeID  132609  132613   ...    135080  135081  135082  135085  135086  \\\n",
       "userID                    ...                                             \n",
       "U1001       NaN     NaN   ...       NaN     NaN     NaN     0.0     NaN   \n",
       "U1002       NaN     NaN   ...       NaN     NaN     NaN     1.0     NaN   \n",
       "U1003       NaN     NaN   ...       2.0     NaN     NaN     NaN     NaN   \n",
       "U1004       NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "U1005       NaN     NaN   ...       NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "placeID  135088  135104  135106  135108  135109  \n",
       "userID                                           \n",
       "U1001       NaN     NaN     NaN     NaN     NaN  \n",
       "U1002       NaN     NaN     1.0     NaN     NaN  \n",
       "U1003       NaN     NaN     NaN     NaN     NaN  \n",
       "U1004       NaN     NaN     2.0     NaN     NaN  \n",
       "U1005       NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_crosstab = pd.pivot_table(data=frame, values='rating', index='userID', columns='placeID')\n",
    "places_crosstab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2487: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n",
      "//anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:2496: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  c *= 1. / np.float64(fact)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PearsonR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>placeID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132572</th>\n",
       "      <td>-0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132723</th>\n",
       "      <td>0.301511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132754</th>\n",
       "      <td>0.930261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132825</th>\n",
       "      <td>0.700745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132834</th>\n",
       "      <td>0.814823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PearsonR\n",
       "placeID          \n",
       "132572  -0.428571\n",
       "132723   0.301511\n",
       "132754   0.930261\n",
       "132825   0.700745\n",
       "132834   0.814823"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Evaluating Similarity Based on Correlation\n",
    "Tortas_ratings = places_crosstab[135085]\n",
    "similar_to_Tortas = places_crosstab.corrwith(Tortas_ratings)\n",
    "\n",
    "corr_Tortas = pd.DataFrame(similar_to_Tortas, columns=['PearsonR'])\n",
    "corr_Tortas.dropna(inplace=True)\n",
    "corr_Tortas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 -  Machine Learning Based Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification-based Collaborative Filtering Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Logistic Regression as a Classifier\n",
    " \n",
    " This bank marketing dataset is open-sourced and available for download at the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#).\n",
    "\n",
    "It was originally created by: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    " ```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# data\n",
    "bank_full = pd.read_csv('bank_full_w_dummy_vars.csv')\n",
    "X = bank_full.ix[:,(18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36)].values\n",
    "y = bank_full.ix[:,17].values\n",
    "# fit\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X, y)\n",
    "# predict\n",
    "new_user = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "y_pred = LogReg.predict(new_user)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based Collaborative Filtering Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD Matrix Factorization\n",
    "\n",
    "The MovieLens dataset was collected by the GroupLens Research Project at the University of Minnesota. You can download the dataset for this demostration at the following URL: https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "``` python\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# data \n",
    "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "frame = pd.read_csv('ml-100k/u.data', sep='\\t', names=columns)\n",
    "columns = ['item_id', 'movie title', 'release date', 'video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    "          'Animation', 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=columns, encoding='latin-1')\n",
    "movie_names = movies[['item_id', 'movie title']]\n",
    "combined_movies_data = pd.merge(frame, movie_names, on='item_id')\n",
    "combined_movies_data.groupby('item_id')['rating'].count().sort_values(ascending=False).head()\n",
    "rating_crosstab = combined_movies_data.pivot_table(values='rating', index='user_id', columns='movie title', fill_value=0)\n",
    "# fit\n",
    "X = rating_crosstab.T\n",
    "SVD = TruncatedSVD(n_components=12, random_state=17)\n",
    "resultant_matrix = SVD.fit_transform(X)\n",
    "corr_mat = np.corrcoef(resultant_matrix)\n",
    "# predict \n",
    "movie_names = rating_crosstab.columns\n",
    "movies_list = list(movie_names)\n",
    "star_wars = movies_list.index('Star Wars (1977)')\n",
    "corr_star_wars = corr_mat[1398]\n",
    "list(movie_names[(corr_star_wars<1.0) & (corr_star_wars > 0.9)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest Neighbors Algorithm\n",
    "\n",
    "*mtcars dataset source:* \n",
    "Henderson and Velleman (1981), Building multiple regression models interactively. Biometrics, 37, 391–411.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# data \n",
    "cars = pd.read_csv('mtcars.csv')\n",
    "t = [15, 300, 160, 3.2]\n",
    "X = cars.ix[:,(1, 3, 4, 6)]\n",
    "# fit \n",
    "nbrs = NearestNeighbors(n_neighbors=1).fit(X)\n",
    "nbrs.kneighbors([t])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 -  Evaluating Recommendation Systems\n",
    "\n",
    "This bank marketing dataset is open-sourced and available for download at the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#).\n",
    "\n",
    "It was originally created by: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_full = pd.read_csv('bank_full_w_dummy_vars.csv')\n",
    "X = bank_full.ix[:,(18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36)].values\n",
    "y = bank_full.ix[:,17].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X, y)\n",
    "y_pred = LogReg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94     39922\n",
      "          1       0.67      0.17      0.27      5289\n",
      "\n",
      "avg / total       0.87      0.89      0.86     45211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
